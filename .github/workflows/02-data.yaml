name: 02 Data Acquisition

on:
  push:
    branches: [main]
    paths-ignore: ['docs/**', 'README.md']
  workflow_dispatch:

jobs:
  acquire-data:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: DeterminateSystems/nix-installer-action@v9
      - uses: DeterminateSystems/magic-nix-cache-action@v2
      - uses: cachix/cachix-action@v14
        with:
          name: johngavin
          authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
          extraPullNames: rstats-on-nix

      - name: Restore Previous Data
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Find latest successful run ID for this workflow to restore state
          RUN_ID=$(gh run list --workflow 02-data.yaml --status success --limit 1 --json databaseId --jq '.[0].databaseId')
          
          if [ -n "$RUN_ID" ]; then
            echo "Restoring state from Run ID: $RUN_ID"
            # Attempt download, but don't fail if artifact is missing (e.g. expired)
            gh run download $RUN_ID -n raw-data-store || echo "No previous artifact found or download failed. Starting fresh."
            
            # Move contents if downloaded into a subdir
            if [ -d "raw-data-store" ]; then
               cp -r raw-data-store/* .
               rm -rf raw-data-store
            fi
          else
            echo "No previous successful run found. Starting fresh."
          fi

      - name: Run Data Targets
        run: |
          # We run only the data acquisition targets
          nix-shell --pure default_ci.nix --run "Rscript -e 'targets::tar_make(c(\"s3_manifest\", \"rna_sample_files\", \"clinical_data\"), callr_function = NULL)'"

      - name: Upload Data Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: raw-data-store
          # We need both the data files and the targets metadata tracking them
          path: |
            _targets/
            data/
          retention-days: 1
